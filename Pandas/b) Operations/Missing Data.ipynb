{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07729424",
   "metadata": {},
   "source": [
    "---\n",
    "# Missing Data in Pandas\n",
    "\n",
    "\n",
    "---\n",
    "## 1. Missing Data - Definition:\n",
    "Data comes in many shapes and forms and more often than not, missing data is one of the biggest issues we encounter in real life! This is why Pandas aims to be flexible with regards to handling it. But before we learn about the ways to handle missing data, let's take a look at some definitions:\n",
    "\n",
    "1. __NaN (Not a Number)__ - a numerical value that best refers to cases of __numerical invalidity__\n",
    "2. __None (NoneType)__ - an internal Python data type, which refers to __inexistent__ or __empty__ values\n",
    "\n",
    "While __NaN__ is the default missing value marker, we need to be able to easily detect and handle this value with data of different data types - float, integer, boolean, etc. This is why we also conside __None__ to be flagging __missing, not avaiable, or NA__ values too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b81e1",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Handling Missing Data:\n",
    "\n",
    "__Why is it important to handle missing data?__ - there are countless reasons to consider Missing Data an 'Enemy' to any data set or analysis.\n",
    "\n",
    "1. Missing data can indicate:\n",
    "    - data collection errors\n",
    "    - calculation errors\n",
    "    - incomplete data collection/implementation\n",
    "    \n",
    "\n",
    "2. Missing data can have:\n",
    "    - an adverse impact on the quality of __Deterministic Models__ (e.g. Machine Learning Models)\n",
    "    - negative consequences to businesses and sectors from a regulatory standpoint\n",
    "    \n",
    "__How to handle missing data?__ - in this unit we will explore two of the most commonly used methods to handle missing data:\n",
    "- Dropping Values\n",
    "- Imputation (filling in with a value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d59c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe239824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that constructs a DataFrame using the .reshape() function\n",
    "# Note that our function assigns nan values to certain DataFrame cells\n",
    "def make_df3():\n",
    "    data = np.array(range(24)).reshape(-1,3)\n",
    "    df   = pd.DataFrame(data, columns=['col1', 'col2', 'col3'])\n",
    "    df.iloc[0,1] = np.nan\n",
    "    df.iloc[4,0] = np.nan\n",
    "    df.iloc[6,0] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a demo DataFrame\n",
    "df = make_df3()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5aaf49",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Dropping:\n",
    "__Dropping Missing Values__ is the the second 'easiest way' to handle missing data to simply leaving it in the data set! Dropping refers to 'getting rid of' any records that contain a missing value - be it columns or rows in a DataFrame. \n",
    "\n",
    "However, the ease of this method comes at the expense of a high risk of losing important data points - often this is critical from a business point of view! Therefore dropping must be conducted carefully and very selectively!\n",
    "\n",
    "To perform dropping of values, we use Pandas `.dropna()` function:\n",
    "- `df_name.dropna(axis = 1)` - drops all columns with missing values\n",
    "- `df_name.dropna(axis = 0)` - drops all rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames using different axis values:\n",
    "\n",
    "# df1 will contain only non-null columns of df\n",
    "df1 = df.dropna(axis = 1)\n",
    "display(df1)\n",
    "\n",
    "# df2 will contain only non-null rows of df\n",
    "df2 = df.dropna(axis = 0)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e84e4b",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Imputation (filling in values):\n",
    "__Imputation__ is the second and most widely used method when it comes to handling missing data. __Impute__ means to __assign (ascribe)__ to something, and in that sense, __Imputation__ simply means to fill in the blanks of a data set. \n",
    "\n",
    "There are multiple approaches to Data Imputation:\n",
    "- Manual Imputation with a single static value\n",
    "- Imputation with multiple static values\n",
    "- Automatic Imputation using __forward fill__ and __backward fill__ aproach\n",
    "\n",
    "All of these approaches leverage the `.fillna()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in all blanks with a single value\n",
    "df.fillna(9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in a column's blanks with a single value using a mask\n",
    "# note - here we use the .isnull() method and explicit indexing\n",
    "mask = df['col1'].isnull()\n",
    "df.loc[mask, 'col1'] = 9000\n",
    "display(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3798884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in columns' blanks with different values\n",
    "df = make_df3()\n",
    "df.fillna({'col1':6666, 'col2': 33333})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4cd26",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1 Forward Fill:\n",
    "__Forward Fill__ is a method, which can be passed on to the __.fillna()__ function.\n",
    "\n",
    "__Forward Fill__ will propagate the last valid observation forward to the missing data point. Essentially, this means that all missing values will be replaced with the value above them in their corresponding column. If the missing value is the first element in a column, it will remain __NaN__.\n",
    "\n",
    "Syntax: \n",
    "- `df_name.fillna(method = 'ffill')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a281cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill\n",
    "df = make_df3()\n",
    "print('Before:')\n",
    "display(df)\n",
    "print('---------------------')\n",
    "print('After:')\n",
    "display(df.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e27f2a",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2 Backward Fill:\n",
    "__Backward Fill__ is a method, which can be passed on to the __.fillna()__ function.\n",
    "\n",
    "__Backward Fill__ works in the opposite way to Forward Fill - it fills in a missing data field with the value beneath them in their corresponding column. If the missing value is the last element in a column, it will remain __NaN__.\n",
    "\n",
    "Syntax: \n",
    "- `df_name.fillna(method = 'bfill')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward fill\n",
    "df = make_df3()\n",
    "print('Before:')\n",
    "display(df)\n",
    "print('---------------------')\n",
    "print('After:')\n",
    "display(df.fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865220b4",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Interpolation:\n",
    "__Interpolation__ is a method of finding a simple function from a given data set, which can then be used to derive data points in between the given data ones. There are many interpolation methods, but we will consider the simples one - __linear interpolation__. \n",
    "\n",
    "A __Linear Interpolation__ will take the two closest values to a missing data field and will 'fill in the blank' with the mid-point (or average) of the two.\n",
    "\n",
    "Syntax:\n",
    "- `df_name.interpolate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation\n",
    "df = make_df3()\n",
    "print('Before:')\n",
    "display(df)\n",
    "print('---------------------')\n",
    "print('After:')\n",
    "display(df.interpolate())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when there are multiple adjasent blanks, interpolate() will take this into account and assign equidistant values\n",
    "pd.Series([1,np.nan,np.nan,4]).interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0deb8e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary:\n",
    "- Handling missing data is important, as it can indicate incomplete data sets, calculation errors, as well as negatively impact data analyses\n",
    "- The two main methods to handle missing data is by __Dropping Values__ and __Imputation (filling in blanks)__\n",
    "- When handling missing data, always pick the most adequate and relevant method to your data set in order to minimise critical data loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39907d66",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Concept Check:\n",
    "\n",
    "1. Suppose we have a DataFrame `df=pd.DataFrame({'col1':[1,2,np.nan, 4,5], 'col2':[6,7,8,9,10], 'col3':[np.nan, 12,13, np.nan,15]})`. Without running a code, determine:\n",
    "- the shape of the output produced by `df.dropna(axis=1)`\n",
    "- the shape of the output produced by `df.dropna(axis=0)`\n",
    "2. Using the DataFrame from question 1 and without running a code, determine:\n",
    "- the value of `df.loc[0,'col3']` after applying imputation via forward fill `.fillna(method = 'ffill')`\n",
    "- the value of `df.loc[2,'col1']` after applying imputation via backward fill `.fillna(method = 'bfill')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a348d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
